---
phase: 07-production-hardening
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - app/services/data_retention.py
  - app/services/failure_tracker.py
  - app/services/telegram_notifier.py
  - app/workers/jobs.py
  - app/workers/scheduler.py
autonomous: true

must_haves:
  truths:
    - "M15 candles older than 90 days are automatically deleted daily"
    - "H1 candles older than 365 days are automatically deleted daily"
    - "H4 and D1 candles are never pruned"
    - "Backtest results older than 180 days are automatically pruned"
    - "After 3+ consecutive API failures, a Telegram system alert is sent"
    - "Database connection failures in jobs skip the cycle and retry on next tick"
    - "Daily health digest is sent via Telegram at 06:00 UTC"
  artifacts:
    - path: "app/services/data_retention.py"
      provides: "Retention service with configurable thresholds per timeframe"
      exports: ["DataRetentionService"]
    - path: "app/services/failure_tracker.py"
      provides: "Consecutive failure counter per job with threshold alerting"
      exports: ["FailureTracker"]
    - path: "app/services/telegram_notifier.py"
      provides: "System alert methods for operational notifications"
      contains: "notify_system_alert"
    - path: "app/workers/jobs.py"
      provides: "Retention job, health digest job, failure tracking wiring"
      contains: "run_data_retention"
    - path: "app/workers/scheduler.py"
      provides: "Registered retention and health digest cron jobs"
      contains: "run_data_retention"
  key_links:
    - from: "app/services/failure_tracker.py"
      to: "app/services/telegram_notifier.py"
      via: "notify_system_alert on threshold breach"
      pattern: "notify_system_alert"
    - from: "app/workers/jobs.py"
      to: "app/services/data_retention.py"
      via: "run_data_retention job function"
      pattern: "DataRetentionService"
    - from: "app/workers/scheduler.py"
      to: "app/workers/jobs.py"
      via: "CronTrigger registration for retention and health digest"
      pattern: "run_data_retention"
---

<objective>
Implement data retention policies, failure tracking with Telegram system alerts, and a daily health digest.

Purpose: Manage database storage growth by pruning old low-timeframe candle data, detect operational issues via consecutive failure tracking with alerts, and provide a daily Telegram summary of system health.

Output: DataRetentionService, FailureTracker, system alert Telegram methods, scheduled retention + health digest jobs
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-production-hardening/07-RESEARCH.md
@app/models/candle.py
@app/models/backtest_result.py
@app/models/signal.py
@app/models/outcome.py
@app/services/telegram_notifier.py
@app/services/candle_ingestor.py
@app/workers/jobs.py
@app/workers/scheduler.py
@app/database.py
@app/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: DataRetentionService and FailureTracker</name>
  <files>app/services/data_retention.py, app/services/failure_tracker.py, app/services/telegram_notifier.py</files>
  <action>
    Create app/services/data_retention.py:

    ```python
    class DataRetentionService:
        """Prunes old candle and backtest data based on configurable retention policies."""

        # Retention thresholds (days) per timeframe
        RETENTION_DAYS = {
            "M15": 90,    # ~8,640 rows max
            "H1": 365,    # ~8,640 rows max
            # H4 and D1: retained indefinitely (not in dict = no pruning)
        }
        BACKTEST_RETENTION_DAYS = 180

        async def run(self, session: AsyncSession) -> dict[str, int]:
            """Delete candles and backtest results beyond retention thresholds.

            Returns dict mapping category to number of rows deleted.
            Example: {"M15_candles": 142, "H1_candles": 0, "backtest_results": 5}
            """
            results = {}
            now = datetime.now(timezone.utc)

            # Prune candles by timeframe
            for timeframe, days in self.RETENTION_DAYS.items():
                cutoff = now - timedelta(days=days)
                stmt = delete(Candle).where(
                    Candle.timeframe == timeframe,
                    Candle.timestamp < cutoff,
                )
                result = await session.execute(stmt)
                results[f"{timeframe}_candles"] = result.rowcount

            # Prune old backtest results
            backtest_cutoff = now - timedelta(days=self.BACKTEST_RETENTION_DAYS)
            stmt = delete(BacktestResult).where(
                BacktestResult.created_at < backtest_cutoff,
            )
            result = await session.execute(stmt)
            results["backtest_results"] = result.rowcount

            await session.commit()
            return results
    ```

    Use SQLAlchemy delete() (not raw SQL). Import from sqlalchemy import delete.
    Signals and Outcomes are NEVER pruned (low volume, valuable history).

    Create app/services/failure_tracker.py:

    ```python
    class FailureTracker:
        """Tracks consecutive failures per job and triggers alerts at threshold.

        Class-level state (not DB) since app is single-process with MemoryJobStore.
        Same pattern as FeedbackController circuit breaker state.
        """

        ALERT_THRESHOLD = 3  # Send alert after N consecutive failures

        _counters: dict[str, int] = {}       # job_id -> consecutive failures
        _alerted: dict[str, bool] = {}       # job_id -> whether alert already sent

        @classmethod
        def record_failure(cls, job_id: str) -> int:
            """Record a failure for a job. Returns new consecutive failure count."""
            cls._counters[job_id] = cls._counters.get(job_id, 0) + 1
            return cls._counters[job_id]

        @classmethod
        def record_success(cls, job_id: str) -> None:
            """Reset failure counter on success."""
            cls._counters[job_id] = 0
            cls._alerted[job_id] = False

        @classmethod
        def should_alert(cls, job_id: str) -> bool:
            """Return True if failure count >= threshold and alert not yet sent."""
            count = cls._counters.get(job_id, 0)
            already_alerted = cls._alerted.get(job_id, False)
            if count >= cls.ALERT_THRESHOLD and not already_alerted:
                cls._alerted[job_id] = True
                return True
            return False

        @classmethod
        def get_count(cls, job_id: str) -> int:
            """Return current consecutive failure count for a job."""
            return cls._counters.get(job_id, 0)

        @classmethod
        def reset_all(cls) -> None:
            """Reset all counters (for testing)."""
            cls._counters.clear()
            cls._alerted.clear()
    ```

    Add system alert methods to app/services/telegram_notifier.py:

    Add two new methods to the TelegramNotifier class:

    1. format_system_alert(self, title: str, details: str) -> str:
       - Format: Warning emoji + bold title + details in italic
       - HTML parse mode (consistent with all other Telegram messages)

    2. notify_system_alert(self, title: str, details: str) -> None:
       - Fire-and-forget wrapper (same pattern as notify_signal, notify_outcome)
       - Checks self.enabled first
       - Logs success/failure

    3. format_health_digest(self, stats: dict) -> str:
       - Format a daily health digest with sections for:
         - Active signals count
         - Signals generated today
         - Outcomes today (wins/losses)
         - Data retention stats (if any pruning happened)
         - Scheduler status (all jobs running)
         - Last candle fetch timestamp
       - Use HTML formatting consistent with existing Telegram messages

    4. notify_health_digest(self, stats: dict) -> None:
       - Fire-and-forget wrapper for health digest
  </action>
  <verify>
    - app/services/data_retention.py exists with DataRetentionService class
    - app/services/failure_tracker.py exists with FailureTracker class
    - grep for "notify_system_alert" in app/services/telegram_notifier.py confirms method exists
    - grep for "notify_health_digest" in app/services/telegram_notifier.py confirms method exists
    - grep for "RETENTION_DAYS" in app/services/data_retention.py confirms retention config
    - grep for "ALERT_THRESHOLD" in app/services/failure_tracker.py confirms threshold
  </verify>
  <done>
    DataRetentionService prunes M15 candles >90d, H1 candles >365d, backtest results >180d. H4/D1 candles and signals/outcomes are never pruned. FailureTracker counts consecutive failures per job and triggers alerts at 3+ failures. TelegramNotifier has notify_system_alert and notify_health_digest methods.
  </done>
</task>

<task type="auto">
  <name>Task 2: Scheduled jobs and failure tracking wiring</name>
  <files>app/workers/jobs.py, app/workers/scheduler.py</files>
  <action>
    Update app/workers/jobs.py -- add three new job functions and wire failure tracking into existing jobs:

    1. Add run_data_retention() job function:
       - Creates own session via async_session_factory
       - Instantiates DataRetentionService and calls run()
       - Logs results: how many rows deleted per category
       - Wraps in try/except to prevent scheduler crashes

    2. Add send_health_digest() job function:
       - Creates own session via async_session_factory
       - Gathers stats:
         - Active signals: SELECT count(*) FROM signals WHERE status = 'active'
         - Signals today: SELECT count(*) FROM signals WHERE created_at >= today_start_utc
         - Outcomes today: SELECT count(*) FROM outcomes WHERE created_at >= today_start_utc, grouped by result
         - Last candle fetch: SELECT MAX(timestamp) FROM candles
         - Scheduler running: import scheduler, check scheduler.running
         - Job count: len(scheduler.get_jobs())
       - Sends via TelegramNotifier.notify_health_digest()
       - Wraps in try/except

    3. Wire FailureTracker into refresh_candles():
       - After successful completion: FailureTracker.record_success(f"refresh_candles_{timeframe}")
       - In except block: count = FailureTracker.record_failure(f"refresh_candles_{timeframe}")
       - If FailureTracker.should_alert(f"refresh_candles_{timeframe}"): send system alert via TelegramNotifier
       - Alert title: "Candle Refresh Failing"
       - Alert details: f"{timeframe} refresh has failed {count} consecutive times"

    4. Wire FailureTracker into run_signal_scanner():
       - Same pattern: record_success on success, record_failure + should_alert in except
       - Alert title: "Signal Scanner Failing"

    5. Wire FailureTracker into check_outcomes():
       - Same pattern
       - Alert title: "Outcome Detection Failing"

    IMPORTANT: Do NOT change the existing job logic. Only ADD failure tracking around the existing try/except blocks. The existing except blocks log the exception -- keep that. Add FailureTracker calls alongside.

    Pattern for wiring into existing jobs (e.g., refresh_candles):
    ```python
    async def refresh_candles(timeframe: str) -> None:
        job_id = f"refresh_candles_{timeframe}"
        try:
            # ... existing logic unchanged ...
            FailureTracker.record_success(job_id)
        except Exception:
            logger.exception(...)  # existing
            count = FailureTracker.record_failure(job_id)
            if FailureTracker.should_alert(job_id):
                settings = get_settings()
                notifier = TelegramNotifier(
                    bot_token=settings.telegram_bot_token,
                    chat_id=settings.telegram_chat_id,
                )
                await notifier.notify_system_alert(
                    "Candle Refresh Failing",
                    f"{timeframe} refresh has failed {count} consecutive times",
                )
    ```

    Update app/workers/scheduler.py -- register two new jobs:

    1. Import run_data_retention and send_health_digest from app.workers.jobs
    2. Register run_data_retention with CronTrigger(hour=3, minute=0, timezone="UTC")
       - id="run_data_retention", name="Run data retention"
    3. Register send_health_digest with CronTrigger(hour=6, minute=0, timezone="UTC")
       - id="send_health_digest", name="Send daily health digest"
    4. Update the final log message count from 7 to 9

    IMPORTANT: Keep replace_existing=True on all new jobs (consistent with existing pattern).
    IMPORTANT: Data retention at 03:00 UTC (after backtests at 02:00). Health digest at 06:00 UTC (before London session).
  </action>
  <verify>
    - grep for "run_data_retention" in both app/workers/jobs.py and app/workers/scheduler.py
    - grep for "send_health_digest" in both app/workers/jobs.py and app/workers/scheduler.py
    - grep for "FailureTracker" in app/workers/jobs.py confirms wiring
    - grep for "record_success" in app/workers/jobs.py confirms success tracking
    - grep for "record_failure" in app/workers/jobs.py confirms failure tracking
    - grep for "should_alert" in app/workers/jobs.py confirms alert triggering
    - grep for 'count=9' or 'count={9}' in app/workers/scheduler.py confirms updated job count
    - Start app locally and verify all 9 jobs appear in scheduler: PYTHONPATH=. python -c "from app.workers.scheduler import scheduler, register_jobs; scheduler.start(); register_jobs(); print([j.id for j in scheduler.get_jobs()]); scheduler.shutdown()"
  </verify>
  <done>
    Data retention runs daily at 03:00 UTC, pruning M15 >90d, H1 >365d, backtests >180d. Health digest sends Telegram summary at 06:00 UTC. All existing jobs (refresh_candles, run_signal_scanner, check_outcomes) track consecutive failures and send Telegram system alerts after 3+ consecutive failures. Database connection failures skip the cycle and retry on next scheduled tick (existing try/except pattern preserved). Scheduler registers 9 total jobs.
  </done>
</task>

</tasks>

<verification>
- DataRetentionService deletes only M15 and H1 candles beyond their thresholds; H4/D1/signals/outcomes untouched
- FailureTracker alerts exactly once per failure streak (not every failure)
- FailureTracker resets on success (alert can fire again on next streak)
- Existing job behavior unchanged -- failure tracking is additive only
- All 9 jobs registered in scheduler with correct cron triggers
- Health digest includes active signals, today's signals/outcomes, last candle fetch, scheduler status
</verification>

<success_criteria>
1. DataRetentionService prunes M15 >90d, H1 >365d, backtests >180d; H4/D1 candles and signals/outcomes are never pruned
2. FailureTracker sends Telegram alert after 3+ consecutive failures for any job, resets on success
3. Health digest Telegram message sent daily at 06:00 UTC with operational summary
4. Data retention job runs daily at 03:00 UTC (after backtests at 02:00)
5. Existing job error handling preserved -- failure tracking wiring is additive
</success_criteria>

<output>
After completion, create `.planning/phases/07-production-hardening/07-02-SUMMARY.md`
</output>
